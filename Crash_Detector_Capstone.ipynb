{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bRcTh-VmyXu0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "id": "bRcTh-VmyXu0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tw8InB3ByWY-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, recall_score, accuracy_score, confusion_matrix"
      ],
      "id": "tw8InB3ByWY-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScqJiCYva02S"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "frame_size = (224, 224)\n",
        "num_frames = 16\n",
        "num_classes = 2\n",
        "batch_size = 16\n",
        "epochs = 50\n",
        "classes = ['normal', 'accident']"
      ],
      "id": "ScqJiCYva02S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXOwyIKcyX4l"
      },
      "outputs": [],
      "source": [
        "# Define input shape\n",
        "input_shape = (50, 264, 264, 3)"
      ],
      "id": "kXOwyIKcyX4l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1zkmfWyRO_s"
      },
      "outputs": [],
      "source": [
        "# pre-process the data\n",
        "def preprocess_video(video_path, frame_size, num_frames):\n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "\n",
        "    while len(frames) < num_frames:\n",
        "        success, frame = vidcap.read()\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        frame = cv2.resize(frame, frame_size)\n",
        "        frame = frame / 255.\n",
        "        frames.append(frame)\n",
        "        frame_count += 1\n",
        "\n",
        "    if len(frames) == num_frames:\n",
        "        return np.stack(frames)\n",
        "    else:\n",
        "        return None "
      ],
      "id": "W1zkmfWyRO_s"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaO8KILvPEBL",
        "outputId": "97ab86eb-aa97-419e-b656-f75d66ecad2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "yaO8KILvPEBL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0dT4Q18yX62"
      },
      "outputs": [],
      "source": [
        "# Load video paths\n",
        "train_accident_videos = glob.glob('/content/drive/MyDrive/Dataset/training/accident/*.*')\n",
        "train_normal_videos = glob.glob('/content/drive/MyDrive/Dataset/training/normal/*.*')\n",
        "test_accident_videos = glob.glob('/content/drive/MyDrive/Dataset/testing/accident/*.*')\n",
        "test_normal_videos = glob.glob('/content/drive/MyDrive/Dataset/testing/normal/*.*')"
      ],
      "id": "Z0dT4Q18yX62"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L3pIugvd_kd"
      },
      "outputs": [],
      "source": [
        "# Combine the lists of paths and create labels\n",
        "train_videos = train_accident_videos + train_normal_videos\n",
        "train_labels = [1] * len(train_accident_videos) + [0] * len(train_normal_videos)\n",
        "test_videos = test_accident_videos + test_normal_videos\n",
        "test_labels = [1] * len(test_accident_videos) + [0] * len(test_normal_videos)"
      ],
      "id": "9L3pIugvd_kd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1IhdI8xcNco"
      },
      "outputs": [],
      "source": [
        "# Custom generator\n",
        "def video_generator(video_paths, labels, frame_size, num_frames, batch_size):\n",
        "    while True:\n",
        "        # Shuffle the data\n",
        "        indices = np.arange(len(video_paths))\n",
        "        np.random.shuffle(indices)\n",
        "        video_paths = [video_paths[i] for i in indices]\n",
        "        labels = [labels[i] for i in indices]\n",
        "\n",
        "        # Generate batches\n",
        "        for i in range(0, len(video_paths), batch_size):\n",
        "            batch_videos = []\n",
        "            batch_labels = []\n",
        "\n",
        "            for j in range(i, min(i + batch_size, len(video_paths))):\n",
        "                video_path = video_paths[j]\n",
        "                video = preprocess_video(video_path, frame_size, num_frames)\n",
        "                label = labels[j]\n",
        "\n",
        "                batch_videos.append(video)\n",
        "                batch_labels.append(label)\n",
        "\n",
        "            yield np.stack(batch_videos, axis=0), to_categorical(batch_labels, num_classes)\n"
      ],
      "id": "p1IhdI8xcNco"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AXLM_t6cYKH"
      },
      "outputs": [],
      "source": [
        "# Create generators\n",
        "train_gen = video_generator(train_videos, train_labels, frame_size, num_frames, batch_size)\n",
        "test_gen = video_generator(test_videos, test_labels, frame_size, num_frames, batch_size)"
      ],
      "id": "1AXLM_t6cYKH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNfYXaIbZ9cG"
      },
      "outputs": [],
      "source": [
        "# Defining the model\n",
        "# 3 convolutional layers, 3 max pooling layers, 2 fully connected layers\n",
        "model = Sequential()\n",
        "model.add(Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=(num_frames, *frame_size, 3)))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "model.add(Conv3D(64, kernel_size=(3, 3, 3), activation='relu'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling3D(pool_size=(2, 2, 2), padding='same'))\n",
        "# model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n"
      ],
      "id": "RNfYXaIbZ9cG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0atr3OolaM1I"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.001,\n",
        "    )\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=adam , metrics=['accuracy', tf.keras.metrics.AUC()])"
      ],
      "id": "0atr3OolaM1I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtwoAgFi3hgA",
        "outputId": "be0cfafb-f36f-414a-8f4b-f5cc9a9b84b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 14, 222, 222, 32)  2624      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 7, 111, 111, 32)  0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 5, 109, 109, 64)   55360     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 2, 54, 54, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 2, 54, 54, 128)    221312    \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 1, 27, 27, 128)   0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 93312)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               11944064  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,223,618\n",
            "Trainable params: 12,223,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "DtwoAgFi3hgA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aXAtYve_dCzA"
      },
      "outputs": [],
      "source": [
        "# Calculating steps per epoch and validation steps\n",
        "steps_per_epoch = len(train_videos) // batch_size\n",
        "validation_steps = len(test_videos) // batch_size"
      ],
      "id": "aXAtYve_dCzA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LkyTxEMxZ9mO"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "history = model.fit(train_gen,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=test_gen,\n",
        "                    validation_steps=validation_steps)"
      ],
      "id": "LkyTxEMxZ9mO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDRjQuNRr357"
      },
      "outputs": [],
      "source": [
        "true_labels = []\n",
        "predicted_labels = []\n",
        "\n",
        "for batch_videos, batch_labels in test_gen:\n",
        "    batch_predictions = model.predict(batch_videos)\n",
        "    batch_predicted_labels = np.argmax(batch_predictions, axis=1)\n",
        "    batch_true_labels = np.argmax(batch_labels, axis=1)\n",
        "\n",
        "    true_labels.extend(batch_true_labels)\n",
        "    predicted_labels.extend(batch_predicted_labels)\n",
        "\n",
        "    if len(true_labels) >= len(test_videos):\n",
        "        break\n",
        "\n",
        "true_labels = np.array(true_labels)\n",
        "predicted_labels = np.array(predicted_labels)\n"
      ],
      "id": "WDRjQuNRr357"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "se0MKARnr6Ba"
      },
      "outputs": [],
      "source": [
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "f_measure = f1_score(true_labels, predicted_labels)\n",
        "precision = precision_score(true_labels, predicted_labels)\n",
        "recall = recall_score(true_labels, predicted_labels)\n",
        "auc = roc_auc_score(true_labels, predicted_labels)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(true_labels, predicted_labels).ravel()\n",
        "specificity = tn / (tn + fp)\n",
        "sensitivity = tp / (tp + fn)\n",
        "\n",
        "print(f\"F-measure: {f_measure}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"Specificity: {specificity}\")\n",
        "print(f\"Sensitivity: {sensitivity}\")"
      ],
      "id": "se0MKARnr6Ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28O7au8QaMge"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "model.save('crash_detector_experiment3.h5')"
      ],
      "id": "28O7au8QaMge"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BN1yqCmwaSgN"
      },
      "outputs": [],
      "source": [
        "# Loading the model\n",
        "model = load_model('crash_detector_experiment3.h5')"
      ],
      "id": "BN1yqCmwaSgN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwYuEEtOi-t9"
      },
      "outputs": [],
      "source": [
        "loss, accuracy, auc = model.evaluate(test_gen, steps=validation_steps)\n",
        "print(f\"Test loss: {loss}, Test accuracy: {accuracy} , Test auc: {auc}\")"
      ],
      "id": "VwYuEEtOi-t9"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}